{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech-256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By  http://places2.csail.mit.edu/PAMI_places  (given by Dr.yang)and reference code ,learning the method to generate the training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import cv2\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/content/drive/My Drive/Colab Notebooks/VGG16_Practice/256_ObjectCategories/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = []\n",
    "all_images = []\n",
    "all_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the pictures in each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def make_square(image, min_size=img_size, fill_color=(0, 0, 0, 0)):\n",
    "    size = (min_size, min_size)\n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    background = Image.new('RGB', size, (255, 255, 255, 0))\n",
    "    background.paste(\n",
    "        image, (int((size[0] - image.size[0]) / 2), int((size[1] - image.size[1]) / 2))\n",
    "    )\n",
    "\n",
    "    new_img = np.array(background)\n",
    "    new_img.flatten()\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in range(len(folders)):\n",
    "    folder_paths = path+str(folders[folder])+str('/')\n",
    "    \n",
    "    os.chdir(folder_paths)\n",
    "    image_in_folder = os.listdir()\n",
    "\n",
    "    for image in range(len(image_in_folder)):\n",
    "        img = Image.open(image_in_folder[image])\n",
    "        img = make_square(img)\n",
    "        \n",
    "        all_images.append(img.flatten()/255)\n",
    "        all_classes.append(folders[folder])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading raw data into a pickle file, Divide data such that it is less than 4GB, the advantage of this is that after the test, you no longer need to read the data from the original photo, but directly load pickle file, and then get the train Data and test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(all_images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_df1 = all_images_df[:10000,:]\n",
    "all_images_df2 = all_images_df[10000:20000,:]\n",
    "all_images_df3 = all_images_df[20000:,:]\n",
    "print('all_images_df1:'+str(sys.getsizeof(all_images_df1)))\n",
    "print('all_images_df2:'+str(sys.getsizeof(all_images_df2)))\n",
    "print('all_images_df3:'+str(sys.getsizeof(all_images_df3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pickel dataï¼ŒSave the pickle file, then test it, you can get the train data and test data directly from the pickle file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklepath = 'G:/Caltech256/'\n",
    "os.chdir(picklepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"pickle_all_images_df1.pickle\",\"wb\")\n",
    "pickle.dump(all_images_df1, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickle_all_images_df2.pickle\",\"wb\")\n",
    "pickle.dump(all_images_df2, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickle_all_images_df3.pickle\",\"wb\")\n",
    "pickle.dump(all_images_df3, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickle_all_classes.pickle\",\"wb\")\n",
    "pickle.dump(all_classes, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
